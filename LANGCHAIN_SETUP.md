# ğŸ¦œ LangChainç‰ˆæœ¬é…ç½®æŒ‡å—

## ğŸ“ æ–°ç‰ˆæœ¬ç‰¹ç‚¹

ä½¿ç”¨LangChainé‡æ„åçš„ç‰ˆæœ¬å…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š

âœ… **ä¸“ä¸šçš„Agentæ¶æ„** - åŸºäºLangChainçš„Agentæ¡†æ¶  
âœ… **æ›´å¥½çš„æç¤ºè¯ç®¡ç†** - ä½¿ç”¨ChatPromptTemplate  
âœ… **è®°å¿†åŠŸèƒ½** - é›†æˆConversationBufferMemory  
âœ… **å¤šLLMæ”¯æŒ** - è½»æ¾åˆ‡æ¢ä¸åŒçš„LLMæä¾›å•†  
âœ… **å…¼å®¹OpenAIæ¥å£** - ModelScopeä½¿ç”¨OpenAIå…¼å®¹æ¥å£  
âœ… **æ›´å¥½çš„é”™è¯¯å¤„ç†** - è‡ªåŠ¨é™çº§åˆ°fallbackæ¨¡å¼  

---

## ğŸ”‘ é‡è¦ï¼šè·å–ModelScope Access Token

### âš ï¸ æ³¨æ„åŒºåˆ«

- **æ—§ç‰ˆAPI Key** (ä¸å†ä½¿ç”¨): `ms-xxx` æ ¼å¼
- **æ–°ç‰ˆAccess Token** (æ¨è): æ›´é•¿çš„å­—ç¬¦ä¸²æ ¼å¼

### è·å–Access Tokençš„æ­¥éª¤

1. **è®¿é—®ModelScopeä¸ªäººä¸­å¿ƒ**
   ```
   https://modelscope.cn/my/myaccesstoken
   ```

2. **åˆ›å»ºæˆ–æŸ¥çœ‹Access Token**
   - ç‚¹å‡»"åˆ›å»ºä»¤ç‰Œ"æˆ–æŸ¥çœ‹ç°æœ‰ä»¤ç‰Œ
   - å¤åˆ¶å®Œæ•´çš„Access Token
   - âš ï¸ ä¿å¯†ä¿å­˜ï¼ä¸è¦åˆ†äº«æˆ–æäº¤åˆ°Git

3. **Tokenç¤ºä¾‹æ ¼å¼**
   ```
   ä½ çš„tokenåº”è¯¥ç±»ä¼¼è¿™æ ·çš„é•¿å­—ç¬¦ä¸²
   ï¼ˆä¸æ˜¯ ms-xxx æ ¼å¼ï¼‰
   ```

---

## ğŸ› ï¸ é…ç½®æ–¹æ³•

### æ–¹æ³•1ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡ï¼ˆæ¨èï¼‰

1. **åˆ›å»º.envæ–‡ä»¶**
   ```powershell
   cd E:\workspace\study\werewolf
   New-Item -ItemType File -Path .env -Force
   notepad .env
   ```

2. **åœ¨.envæ–‡ä»¶ä¸­æ·»åŠ **
   ```env
   # ModelScopeé…ç½®ï¼ˆæ¨èï¼‰
   MODELSCOPE_ACCESS_TOKEN=your-access-token-here
   
   # æˆ–ä½¿ç”¨OpenAI
   OPENAI_API_KEY=sk-your-openai-key-here
   ```

3. **è¿è¡Œæ¸¸æˆ**
   ```powershell
   python werewolf_langchain.py
   ```

### æ–¹æ³•2ï¼šç›´æ¥åœ¨ä»£ç ä¸­é…ç½®ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰

ç¼–è¾‘ `werewolf_langchain.py` æ–‡ä»¶ï¼Œæ‰¾åˆ°ç¬¬59-62è¡Œï¼š

```python
@dataclass
class LLMConfig:
    """LLMé…ç½®"""
    provider: LLMProvider = LLMProvider.MODELSCOPE
    
    # ModelScopeé…ç½®
    modelscope_token: str = "your-actual-token-here"  # ğŸ‘ˆ å¡«å…¥ä½ çš„token
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ­¥éª¤1ï¼šæ¿€æ´»Condaç¯å¢ƒ

```powershell
conda activate werewolf
cd E:\workspace\study\werewolf
```

### æ­¥éª¤2ï¼šæµ‹è¯•LLMè¿æ¥

```powershell
python -c "from werewolf_langchain import LLMConfig, test_llm_connection; config = LLMConfig(); test_llm_connection(config)"
```

### æ­¥éª¤3ï¼šè¿è¡Œæ¸¸æˆ

```powershell
python werewolf_langchain.py
```

---

## ğŸ® ä½¿ç”¨ä¸åŒçš„LLMæä¾›å•†

### ä½¿ç”¨ModelScopeï¼ˆå…è´¹ï¼Œæ¨èï¼‰

```python
from werewolf_langchain import WerewolfGame, LLMConfig, LLMProvider

config = LLMConfig(
    provider=LLMProvider.MODELSCOPE,
    modelscope_token="your-access-token",
    modelscope_model="Qwen/Qwen2.5-7B-Instruct"  # å¯é€‰å…¶ä»–æ¨¡å‹
)

game = WerewolfGame(config)
game.play(max_rounds=3)
```

### ä½¿ç”¨OpenAI

```python
config = LLMConfig(
    provider=LLMProvider.OPENAI,
    openai_api_key="sk-your-key",
    openai_model="gpt-4o-mini"  # æˆ– gpt-4
)

game = WerewolfGame(config)
game.play(max_rounds=3)
```

---

## ğŸ“¦ å¯ç”¨çš„ModelScopeæ¨¡å‹

æ¨èä½¿ç”¨ä»¥ä¸‹æ¨¡å‹ï¼ˆå‡å…¼å®¹OpenAIæ¥å£ï¼‰ï¼š

| æ¨¡å‹ID | å‚æ•°é‡ | ç‰¹ç‚¹ | æ¨èåœºæ™¯ |
|--------|--------|------|---------|
| `Qwen/Qwen2.5-7B-Instruct` | 7B | å¹³è¡¡æ€§èƒ½é€Ÿåº¦ | æ¸¸æˆAIï¼ˆæ¨èï¼‰ |
| `Qwen/Qwen2.5-14B-Instruct` | 14B | æ›´å¼ºæ¨ç†èƒ½åŠ› | å¤æ‚å¯¹è¯ |
| `Qwen/Qwen2.5-32B-Instruct` | 32B | é«˜çº§æ¨ç† | ä¸“ä¸šåº”ç”¨ |
| `Qwen/Qwen2.5-Coder-32B-Instruct` | 32B | ç¼–ç¨‹ç‰¹åŒ– | ä»£ç ç›¸å…³ |

æ›´å¤šæ¨¡å‹ï¼šhttps://modelscope.cn/models

---

## ğŸ”§ é«˜çº§é…ç½®

### è‡ªå®šä¹‰Agentè¡Œä¸º

ç¼–è¾‘ `werewolf_langchain.py` ä¸­çš„Agentç±»ï¼š

```python
class WerewolfAgent:
    def _setup_prompts(self):
        # ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯
        system_template = """ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„ç‹¼äººæ€ç©å®¶ã€‚
        
ã€ä½ çš„é£æ ¼ã€‘
- æ€§æ ¼ï¼šå†·é™ã€å–„äºåˆ†æ
- ç­–ç•¥ï¼šé€»è¾‘æ¨ç†ä¸ºä¸»
- ç‰¹ç‚¹ï¼š{custom_trait}

{role_description}
"""
```

### è°ƒæ•´LLMå‚æ•°

```python
config = LLMConfig(
    provider=LLMProvider.MODELSCOPE,
    temperature=0.9,      # æé«˜åˆ›é€ æ€§ (0.0-1.0)
    max_tokens=800,       # å¢åŠ å›å¤é•¿åº¦
)
```

### æ·»åŠ æ›´å¤šè½®æ¬¡

```python
game.play(max_rounds=5)  # è¿è¡Œ5è½®
```

---

## ğŸ› é—®é¢˜æ’æŸ¥

### é—®é¢˜1ï¼š401 Unauthorized

**åŸå› **: Access Tokenæ— æ•ˆæˆ–è¿‡æœŸ

**è§£å†³**:
1. è®¿é—® https://modelscope.cn/my/myaccesstoken
2. åˆ›å»ºæ–°çš„Access Token
3. æ›´æ–°.envæ–‡ä»¶æˆ–ä»£ç ä¸­çš„token
4. ç¡®ä¿ä½¿ç”¨çš„æ˜¯Access Tokenï¼Œä¸æ˜¯æ—§ç‰ˆAPI Key

### é—®é¢˜2ï¼šImport Error

**åŸå› **: LangChainæœªå®‰è£…

**è§£å†³**:
```powershell
pip install langchain langchain-openai langchain-community
```

### é—®é¢˜3ï¼šç½‘ç»œè¿æ¥å¤±è´¥

**åŸå› **: æ— æ³•è®¿é—®ModelScope API

**è§£å†³**:
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. å¦‚éœ€ä»£ç†ï¼Œè®¾ç½®ç¯å¢ƒå˜é‡ï¼š
   ```powershell
   $env:HTTP_PROXY="http://proxy:port"
   $env:HTTPS_PROXY="http://proxy:port"
   ```
3. æˆ–åˆ‡æ¢åˆ°OpenAIï¼š
   ```python
   config = LLMConfig(provider=LLMProvider.OPENAI)
   ```

### é—®é¢˜4ï¼šLLMå“åº”æ…¢

**åŸå› **: æ¨¡å‹å¤ªå¤§æˆ–ç½‘ç»œæ…¢

**è§£å†³**:
1. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼š
   ```python
   modelscope_model="Qwen/Qwen2.5-7B-Instruct"
   ```
2. å‡å°‘max_tokensï¼š
   ```python
   max_tokens=200
   ```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. ç¯å¢ƒå˜é‡ç®¡ç†

åˆ›å»º `.env` æ–‡ä»¶ï¼ˆæ¨èï¼‰ï¼š
```env
MODELSCOPE_ACCESS_TOKEN=your-token
OPENAI_API_KEY=your-key

# å¯é€‰é…ç½®
MODELSCOPE_MODEL=Qwen/Qwen2.5-7B-Instruct
LLM_TEMPERATURE=0.8
LLM_MAX_TOKENS=500
```

### 2. Gitå¿½ç•¥æ•æ„Ÿä¿¡æ¯

ç¡®ä¿ `.gitignore` åŒ…å«ï¼š
```gitignore
.env
*.env
*token*
*secret*
```

### 3. é”™è¯¯å¤„ç†

ä»£ç å·²åŒ…å«è‡ªåŠ¨é™çº§ï¼š
- LLMè°ƒç”¨å¤±è´¥ â†’ ä½¿ç”¨fallbackå›å¤
- æŠ•ç¥¨è§£æå¤±è´¥ â†’ éšæœºé€‰æ‹©
- ç½‘ç»œé”™è¯¯ â†’ æ˜¾ç¤ºå‹å¥½æç¤º

### 4. æˆæœ¬æ§åˆ¶

ModelScopeå…è´¹é¢åº¦æœ‰é™ï¼Œå»ºè®®ï¼š
- å¼€å‘æ—¶ä½¿ç”¨è¾ƒå°æ¨¡å‹
- æ§åˆ¶max_tokensæ•°é‡
- ç›‘æ§APIä½¿ç”¨é‡

---

## ğŸ“Š ä¸æ—§ç‰ˆå¯¹æ¯”

| ç‰¹æ€§ | æ—§ç‰ˆ | LangChainç‰ˆæœ¬ |
|------|------|--------------|
| Agentæ¡†æ¶ | è‡ªå®šä¹‰ | LangChain Agent |
| æç¤ºè¯ç®¡ç† | å­—ç¬¦ä¸²æ‹¼æ¥ | ChatPromptTemplate |
| è®°å¿†åŠŸèƒ½ | ç®€å•åˆ—è¡¨ | ConversationBufferMemory |
| LLMåˆ‡æ¢ | ç¡¬ç¼–ç  | é…ç½®åŒ–åˆ‡æ¢ |
| é”™è¯¯å¤„ç† | åŸºç¡€ | å®Œå–„çš„é™çº§æœºåˆ¶ |
| ä»£ç ç»„ç»‡ | å•æ–‡ä»¶ | æ¨¡å—åŒ–è®¾è®¡ |
| å¯æ‰©å±•æ€§ | ä¸­ç­‰ | é«˜ |

---

## ğŸ”— ç›¸å…³èµ„æº

### å®˜æ–¹æ–‡æ¡£
- **ModelScope**: https://modelscope.cn/docs
- **ModelScope API**: https://www.modelscope.cn/docs/api-inference/intro
- **LangChain**: https://python.langchain.com/
- **LangChain ChatOpenAI**: https://python.langchain.com/docs/integrations/chat/openai

### è·å–Token
- **ModelScope Access Token**: https://modelscope.cn/my/myaccesstoken
- **OpenAI API Key**: https://platform.openai.com/api-keys

### ç¤¾åŒº
- **ModelScopeç¤¾åŒº**: https://modelscope.cn/community
- **LangChain GitHub**: https://github.com/langchain-ai/langchain

---

## ğŸ“ å¿«é€Ÿå‘½ä»¤å‚è€ƒ

```powershell
# æ¿€æ´»ç¯å¢ƒ
conda activate werewolf

# è¿›å…¥é¡¹ç›®ç›®å½•
cd E:\workspace\study\werewolf

# æµ‹è¯•LLMè¿æ¥
python -c "from werewolf_langchain import test_llm_connection, LLMConfig; test_llm_connection(LLMConfig())"

# è¿è¡Œæ¸¸æˆ
python werewolf_langchain.py

# æŸ¥çœ‹å·²å®‰è£…åŒ…
pip list | Select-String "langchain|openai"

# æ›´æ–°LangChain
pip install --upgrade langchain langchain-openai
```

---

**é…ç½®å®Œæˆæ—¶é—´**: 2025-11-03  
**æ¨èé…ç½®**: ModelScope + Qwen2.5-7B-Instruct  
**éœ€è¦å¸®åŠ©**: æŸ¥çœ‹ [MODELSCOPE_GUIDE.md](./MODELSCOPE_GUIDE.md)



