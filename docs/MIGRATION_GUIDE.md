# è¿ç§»æŒ‡å— - v2.0 é…ç½®ç³»ç»Ÿé‡æ„

## æ¦‚è¿°

æœ¬æ¬¡é‡æ„é‡‡ç”¨äº† **LangChain è§„èŒƒ**ï¼Œå¹¶å®Œå…¨é‡å†™äº†é…ç½®ç³»ç»Ÿã€‚å¦‚æœä½ ä¹‹å‰ä½¿ç”¨çš„æ˜¯æ—§ç‰ˆæœ¬ï¼Œè¯·æŒ‰ç…§æœ¬æŒ‡å—è¿ç§»ã€‚

---

## ä¸»è¦å˜åŒ–

### 1. é…ç½®ç³»ç»Ÿé‡æ„ âœ¨

**æ—§ç‰ˆæœ¬**ï¼š
```python
# é…ç½®åˆ†æ•£åœ¨å¤šä¸ªåœ°æ–¹ï¼Œéš¾ä»¥ç®¡ç†
config.modelscope_token = "xxx"
config.tts_voice = "xxx"
```

**æ–°ç‰ˆæœ¬**ï¼š
```python
# ç»Ÿä¸€é…ç½®ç®¡ç†ï¼Œæ”¯æŒå¤šæä¾›å•†
from src.utils.config import get_config

config = get_config()
llm_config = config.get_llm_config()  # è·å–LLMé…ç½®
tts_config = config.get_tts_config()  # è·å–TTSé…ç½®
```

### 2. ç¯å¢ƒå˜é‡ä¼˜å…ˆçº§ ğŸ”¥

**æ—§ç‰ˆæœ¬**ï¼šé…ç½®æ–‡ä»¶ä¼˜å…ˆ

**æ–°ç‰ˆæœ¬**ï¼šç¯å¢ƒå˜é‡ > é…ç½®æ–‡ä»¶ > é»˜è®¤å€¼

```bash
# .env æ–‡ä»¶ä¸­çš„é…ç½®ä¼šè¦†ç›– default.json
LLM_PROVIDER=openai
LLM_TEMPERATURE=0.9
```

### 3. LLMå·¥å‚æ¨¡å¼ ğŸ­

**æ—§ç‰ˆæœ¬**ï¼š
```python
llm = ChatOpenAI(
    api_key=config.openai_api_key,
    model=config.openai_model,
    temperature=0.8
)
```

**æ–°ç‰ˆæœ¬**ï¼š
```python
from src.agents.agent_factory import LLMFactory

# è‡ªåŠ¨ä»é…ç½®åˆ›å»ºï¼Œæ”¯æŒå¤šæä¾›å•†
llm = LLMFactory.create_llm()  # ä½¿ç”¨é»˜è®¤æä¾›å•†
llm = LLMFactory.create_llm("openai")  # æŒ‡å®šæä¾›å•†
```

### 4. Agentåˆ›å»ºç®€åŒ– ğŸ¤–

**æ—§ç‰ˆæœ¬**ï¼š
```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(...)
agent = LangChainAgent(player, llm)
```

**æ–°ç‰ˆæœ¬**ï¼š
```python
from src.agents.agent_factory import AgentFactory

# è‡ªåŠ¨åˆ›å»ºLLMå’ŒAgent
agent = AgentFactory.create_agent(player)

# æŒ‡å®šæä¾›å•†
agent = AgentFactory.create_agent(player, provider="openai")
```

### 5. å¤šæä¾›å•†æ”¯æŒ ğŸŒ

**æ—§ç‰ˆæœ¬**ï¼šä»…æ”¯æŒ OpenAI å’Œ ModelScope

**æ–°ç‰ˆæœ¬**ï¼šæ”¯æŒå¤šç§æä¾›å•†
- âœ… OpenAI (gpt-4, gpt-3.5-turbo)
- âœ… DashScope (qwen-plus, qwen-turbo)
- âœ… ModelScope (å…è´¹æ¨ç†)
- âœ… Anthropic (Claudeç³»åˆ—)

---

## è¿ç§»æ­¥éª¤

### ç¬¬1æ­¥ï¼šæ›´æ–°ä¾èµ–

```bash
pip install --upgrade -r requirements.txt
```

### ç¬¬2æ­¥ï¼šåˆ›å»º .env æ–‡ä»¶

```bash
# å¤åˆ¶ç¤ºä¾‹æ–‡ä»¶
cp env.example.txt .env

# ç¼–è¾‘é…ç½®
vim .env
```

å¡«å…¥ä½ çš„API Keyï¼š

```bash
# æ–¹æ¡ˆAï¼šModelScope + DashScopeï¼ˆæ¨èå…è´¹ï¼‰
LLM_PROVIDER=modelscope
OPENAI_API_KEY=ms-your-modelscope-token
OPENAI_API_BASE=https://api-inference.modelscope.cn/v1/
OPENAI_MODEL=Qwen/Qwen2.5-32B-Instruct

DASHSCOPE_API_KEY=sk-your-dashscope-key
TTS_ENABLED=true
TTS_VOICE=Cherry

# æ–¹æ¡ˆBï¼šå…¨éƒ¨ä½¿ç”¨DashScope
# LLM_PROVIDER=dashscope
# OPENAI_API_KEY=sk-your-dashscope-key
# OPENAI_API_BASE=https://dashscope.aliyuncs.com/compatible-mode/v1
# OPENAI_MODEL=qwen-plus
# DASHSCOPE_API_KEY=sk-your-dashscope-key
```

### ç¬¬3æ­¥ï¼šæ›´æ–°é…ç½®æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰

å¦‚æœä½ æœ‰è‡ªå®šä¹‰çš„é…ç½®æ–‡ä»¶ï¼Œè¯·å‚è€ƒæ–°çš„ `config/default.json` ç»“æ„æ›´æ–°ï¼š

```json
{
  "llm": {
    "provider": "modelscope",
    "temperature": 0.8,
    "providers": {
      "openai": {...},
      "dashscope": {...},
      "modelscope": {...}
    }
  },
  "tts": {
    "provider": "dashscope",
    "providers": {
      "dashscope": {...}
    }
  }
}
```

### ç¬¬4æ­¥ï¼šæ›´æ–°ä»£ç 

#### æ—§ä»£ç ï¼š
```python
from src.utils.config import get_config
from langchain_openai import ChatOpenAI
from src.agents import LangChainAgent

config = get_config()

# æ‰‹åŠ¨åˆ›å»ºLLM
llm = ChatOpenAI(
    api_key=config.openai_api_key,
    model=config.openai_model,
    temperature=config.llm_temperature
)

# åˆ›å»ºAgent
agent = LangChainAgent(player, llm)
```

#### æ–°ä»£ç ï¼š
```python
from src.agents.agent_factory import AgentFactory

# ä¸€è¡Œä»£ç æå®šï¼è‡ªåŠ¨ä»é…ç½®åˆ›å»ºLLMå’ŒAgent
agent = AgentFactory.create_agent(player)
```

### ç¬¬5æ­¥ï¼šæµ‹è¯•é…ç½®

```bash
python test_config.py
```

çœ‹åˆ° `âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡` è¡¨ç¤ºè¿ç§»æˆåŠŸï¼

---

## é…ç½®æ–‡ä»¶æ˜ å°„

### ç¯å¢ƒå˜é‡æ˜ å°„

| æ—§å˜é‡ | æ–°å˜é‡ | è¯´æ˜ |
|--------|--------|------|
| `OPENAI_API_KEY` | `OPENAI_API_KEY` | ä¿æŒä¸å˜ |
| `OPENAI_MODEL` | `OPENAI_MODEL` | ä¿æŒä¸å˜ |
| `MODELSCOPE_API_KEY` | `MODELSCOPE_API_KEY` æˆ– `OPENAI_API_KEY` | å…¼å®¹ |
| `MODELSCOPE_MODEL` | `MODELSCOPE_MODEL` æˆ– `OPENAI_MODEL` | å…¼å®¹ |
| `DASHSCOPE_API_KEY` | `DASHSCOPE_API_KEY` | ä¿æŒä¸å˜ |
| `TTS_VOICE` | `TTS_VOICE` | ä¿æŒä¸å˜ |
| `TTS_MODEL` | `TTS_MODEL` | ä¿æŒä¸å˜ |
| `LLM_TEMPERATURE` | `LLM_TEMPERATURE` | ä¿æŒä¸å˜ |
| `LLM_MAX_TOKENS` | `LLM_MAX_TOKENS` | ä¿æŒä¸å˜ |
| - | `LLM_PROVIDER` | **æ–°å¢** é€‰æ‹©LLMæä¾›å•† |
| - | `TTS_PROVIDER` | **æ–°å¢** é€‰æ‹©TTSæä¾›å•† |

### é…ç½®æ–‡ä»¶ç»“æ„å˜åŒ–

**æ—§ç»“æ„** (`default.json`)ï¼š
```json
{
  "llm": {
    "provider": "openai",
    "model": "gpt-4o-mini",
    "temperature": 0.7
  }
}
```

**æ–°ç»“æ„** (`default.json`)ï¼š
```json
{
  "llm": {
    "provider": "modelscope",
    "temperature": 0.8,
    "providers": {
      "openai": {
        "api_key": "",
        "model": "gpt-4o-mini",
        "base_url": "https://api.openai.com/v1"
      },
      "modelscope": {
        "api_key": "",
        "model": "Qwen/Qwen2.5-32B-Instruct",
        "base_url": "https://api-inference.modelscope.cn/v1/"
      }
    }
  }
}
```

---

## APIå˜åŒ–

### é…ç½®API

#### è·å–é…ç½®
```python
# æ—§API
config = Config()
token = config.modelscope_token

# æ–°API
config = get_config()
llm_config = config.get_llm_config()
token = llm_config['api_key']
```

#### é…ç½®éªŒè¯
```python
# æ–°å¢
config.validate()  # è¿”å› True/False
```

### LLMåˆ›å»ºAPI

```python
# æ—§API
from langchain_openai import ChatOpenAI
llm = ChatOpenAI(api_key=xxx, model=xxx)

# æ–°API
from src.agents.agent_factory import LLMFactory
llm = LLMFactory.create_llm()  # è‡ªåŠ¨ä»é…ç½®åˆ›å»º
llm = LLMFactory.create_llm("openai")  # æŒ‡å®šæä¾›å•†
```

### Agentåˆ›å»ºAPI

```python
# æ—§API
agent = LangChainAgent(player, llm)

# æ–°API
from src.agents.agent_factory import AgentFactory
agent = AgentFactory.create_agent(player)
agent = AgentFactory.create_agent(player, provider="openai")
```

---

## å…¼å®¹æ€§è¯´æ˜

### å‘åå…¼å®¹

ä¸ºäº†ä¿æŒå…¼å®¹æ€§ï¼Œæ—§çš„ç¯å¢ƒå˜é‡**ä»ç„¶æœ‰æ•ˆ**ï¼š

```bash
# è¿™äº›ä»ç„¶å¯ç”¨
OPENAI_API_KEY=xxx
OPENAI_MODEL=xxx
MODELSCOPE_API_KEY=xxx
```

ä½†æ¨èä½¿ç”¨æ–°çš„é…ç½®æ–¹å¼ï¼š

```bash
# æ¨è
LLM_PROVIDER=modelscope
OPENAI_API_KEY=ms-xxx  # ç”¨äº ModelScope
DASHSCOPE_API_KEY=sk-xxx  # ç”¨äº TTS
```

### ä¸å…¼å®¹çš„å˜åŒ–

ä»¥ä¸‹åŠŸèƒ½ä¸å†æ”¯æŒæˆ–å·²æ”¹å˜ï¼š

1. âŒ **ç›´æ¥è®¿é—®é…ç½®å±æ€§**
   ```python
   # æ—§æ–¹å¼ï¼ˆä¸æ¨èï¼‰
   config.modelscope_token
   
   # æ–°æ–¹å¼
   config.get_llm_config("modelscope")["api_key"]
   ```

2. âŒ **æ‰‹åŠ¨åˆ›å»ºLLM**
   ```python
   # ä¸æ¨èï¼ˆè™½ç„¶ä»å¯ç”¨ï¼‰
   llm = ChatOpenAI(api_key=xxx, model=xxx)
   
   # æ¨è
   llm = LLMFactory.create_llm()
   ```

---

## å¸¸è§é—®é¢˜

### Q: æ—§çš„ .env æ–‡ä»¶è¿˜èƒ½ç”¨å—ï¼Ÿ

**A**: å¯ä»¥ï¼ä½†å»ºè®®æŒ‰ç…§æ–°æ ¼å¼æ›´æ–°ï¼Œæ·»åŠ  `LLM_PROVIDER` ç­‰æ–°å˜é‡ã€‚

### Q: å¿…é¡»ä½¿ç”¨ .env æ–‡ä»¶å—ï¼Ÿ

**A**: ä¸æ˜¯å¿…é¡»çš„ï¼Œä½†**å¼ºçƒˆæ¨è**ã€‚ä½ ä¹Ÿå¯ä»¥ç›´æ¥ä¿®æ”¹ `config/default.json`ã€‚

### Q: å¦‚ä½•ä»æ—§çš„é…ç½®æ–‡ä»¶è¿ç§»ï¼Ÿ

**A**: 
1. å¤‡ä»½æ—§é…ç½®
2. å¤åˆ¶ `env.example.txt` ä¸º `.env`
3. å°†æ—§é…ç½®çš„å€¼å¡«å…¥æ–°çš„ `.env`
4. è¿è¡Œ `python test_config.py` æµ‹è¯•

### Q: è¿ç§»åæ€§èƒ½æœ‰å˜åŒ–å—ï¼Ÿ

**A**: 
- âœ… é…ç½®åŠ è½½é€Ÿåº¦ï¼šæ— æ˜æ˜¾å·®å¼‚
- âœ… LLMè°ƒç”¨ï¼šæ€§èƒ½ç›¸åŒï¼ˆåªæ˜¯åˆ›å»ºæ–¹å¼ä¸åŒï¼‰
- âœ… å†…å­˜å ç”¨ï¼šç•¥å¾®ä¼˜åŒ–ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

### Q: éœ€è¦ä¿®æ”¹ç°æœ‰ä»£ç å—ï¼Ÿ

**A**: 
- å¦‚æœä½¿ç”¨ `AgentFactory.create_batch_agents()`ï¼š**æ— éœ€ä¿®æ”¹**
- å¦‚æœç›´æ¥åˆ›å»º `LangChainAgent`ï¼š**å»ºè®®æ›´æ–°**ä¸ºæ–°API
- å¦‚æœè¯»å–é…ç½®ï¼š**å»ºè®®æ›´æ–°**ä¸ºæ–°API

---

## è¿ç§»æ£€æŸ¥æ¸…å•

å®Œæˆä»¥ä¸‹æ­¥éª¤ç¡®ä¿è¿ç§»æˆåŠŸï¼š

- [ ] æ›´æ–°ä¾èµ– `pip install --upgrade -r requirements.txt`
- [ ] åˆ›å»º `.env` æ–‡ä»¶å¹¶å¡«å†™é…ç½®
- [ ] æ·»åŠ  `LLM_PROVIDER` å˜é‡
- [ ] æµ‹è¯•é…ç½® `python test_config.py`
- [ ] æ›´æ–°ä»£ç ä½¿ç”¨æ–°APIï¼ˆå¯é€‰ä½†æ¨èï¼‰
- [ ] å¯åŠ¨æœåŠ¡æµ‹è¯• `python main.py`
- [ ] éªŒè¯LLMå’ŒTTSå·¥ä½œæ­£å¸¸

---

## è·å–å¸®åŠ©

- ğŸ“– è¯¦ç»†é…ç½®è¯´æ˜ï¼š[CONFIG_GUIDE.md](./CONFIG_GUIDE.md)
- ğŸ“ ç¤ºä¾‹é…ç½®ï¼š`env.example.txt`
- ğŸ§ª é…ç½®æµ‹è¯•ï¼š`python test_config.py`
- ğŸ’¬ é‡åˆ°é—®é¢˜ï¼Ÿæäº¤ Issue åˆ° GitHub

---

**è¿ç§»æ„‰å¿«ï¼** ğŸš€

å¦‚æœé‡åˆ°ä»»ä½•é—®é¢˜ï¼Œè¯·å…ˆè¿è¡Œ `python test_config.py` è¿›è¡Œè¯Šæ–­ã€‚

