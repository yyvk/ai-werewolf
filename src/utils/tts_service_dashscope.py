"""
è¯­éŸ³åˆæˆæœåŠ¡ - ä½¿ç”¨ DashScope API
é˜¿é‡Œäº‘çš„è¯­éŸ³åˆæˆæœåŠ¡

é‡‡ç”¨æ–°çš„é…ç½®ç³»ç»Ÿï¼Œæ”¯æŒä»é…ç½®æ–‡ä»¶å’Œç¯å¢ƒå˜é‡åŠ è½½é…ç½®
"""

import os
import asyncio
import base64
from typing import Optional, Dict, Any
from pathlib import Path

try:
    import dashscope
    from dashscope.audio.tts import SpeechSynthesizer
    DASHSCOPE_AVAILABLE = True
except ImportError:
    DASHSCOPE_AVAILABLE = False
    print("âš ï¸ dashscope æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install dashscope")


class DashScopeTTSService:
    """DashScope è¯­éŸ³åˆæˆæœåŠ¡ç±»"""
    
    def __init__(
        self, 
        api_key: Optional[str] = None,
        model: Optional[str] = None,
        voice: Optional[str] = None,
        speed: Optional[float] = None,
        pitch: Optional[float] = None,
        use_config: bool = True
    ):
        """
        åˆå§‹åŒ– TTS æœåŠ¡
        
        Args:
            api_key: DashScope APIå¯†é’¥
            model: TTSæ¨¡å‹åç§°
            voice: éŸ³è‰²åç§°
            speed: è¯­é€Ÿï¼ˆ0.5-2.0ï¼‰
            pitch: éŸ³é«˜ï¼ˆ0.5-2.0ï¼‰
            use_config: æ˜¯å¦ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼ˆé»˜è®¤: Trueï¼‰
        """
        if not DASHSCOPE_AVAILABLE:
            raise ImportError("dashscope åº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install dashscope")
        
        # åŠ è½½é…ç½®
        if use_config:
            from src.utils.config import get_config
            config = get_config()
            tts_config = config.get_tts_config("dashscope")
        else:
            tts_config = {}
        
        # å‚æ•°ä¼˜å…ˆçº§ï¼šä¼ å…¥å‚æ•° > é…ç½®æ–‡ä»¶ > é»˜è®¤å€¼
        self.api_key = api_key or tts_config.get("api_key", "")
        self.model = model or tts_config.get("model", "qwen3-tts-flash")
        self.voice = voice or tts_config.get("voice", "Cherry")
        self.speed = speed if speed is not None else tts_config.get("speed", 1.0)
        self.pitch = pitch if pitch is not None else tts_config.get("pitch", 1.0)
        self.volume = tts_config.get("volume", 50)
        self.sample_rate = tts_config.get("sample_rate", 16000)
        self.format = tts_config.get("format", "wav")
        
        # è®¾ç½® DashScope API Key
        if self.api_key:
            dashscope.api_key = self.api_key
        else:
            print("âš ï¸ æœªé…ç½® DashScope API Key")
        
        # è®¾ç½® DashScope API åœ°å€ï¼ˆåŒ—äº¬åœ°åŸŸï¼‰
        dashscope.base_http_api_url = 'https://dashscope.aliyuncs.com/api/v1'
        
        # éŸ³é¢‘è¾“å‡ºç›®å½•
        self.output_dir = Path(__file__).parent.parent.parent / "assets" / "audio"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ”Š DashScope TTSæœåŠ¡åˆå§‹åŒ–:")
        print(f"   æ¨¡å‹: {self.model}")
        print(f"   éŸ³è‰²: {self.voice}")
        print(f"   è¯­é€Ÿ: {self.speed}")
        print(f"   éŸ³é«˜: {self.pitch}")
    
    async def text_to_speech(
        self, 
        text: str, 
        player_id: Optional[int] = None,
        voice: Optional[str] = None,
        speed: Optional[float] = None,
        pitch: Optional[float] = None
    ) -> Optional[str]:
        """
        å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³
        
        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            player_id: ç©å®¶IDï¼ˆç”¨äºç”Ÿæˆæ–‡ä»¶åï¼‰
            voice: éŸ³è‰²ï¼ˆå¯é€‰ï¼Œè¦†ç›–é»˜è®¤éŸ³è‰²ï¼‰
            speed: è¯­é€Ÿï¼ˆå¯é€‰ï¼Œè¦†ç›–é»˜è®¤è¯­é€Ÿï¼‰
            pitch: éŸ³é«˜ï¼ˆå¯é€‰ï¼Œè¦†ç›–é»˜è®¤éŸ³é«˜ï¼‰
        
        Returns:
            éŸ³é¢‘æ–‡ä»¶çš„è·¯å¾„ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
        """
        if not text or not self.api_key:
            return None
        
        # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°æˆ–é»˜è®¤å‚æ•°
        voice = voice or self.voice
        speed = speed if speed is not None else self.speed
        pitch = pitch if pitch is not None else self.pitch
        
        try:
            # ç”Ÿæˆæ–‡ä»¶å
            file_name = f"speech_{player_id}_{hash(text) % 100000}.{self.format}"
            file_path = self.output_dir / file_name
            
            # ä½¿ç”¨é…ç½®çš„ TTS æ¨¡å‹
            try:
                response = dashscope.MultiModalConversation.call(
                    api_key=self.api_key,
                    model=self.model,
                    text=text,
                    voice=voice,
                    language_type="Chinese",
                    stream=True
                )
                
                # æ”¶é›†æ‰€æœ‰éŸ³é¢‘æ•°æ®
                audio_chunks = []
                for chunk in response:
                    if hasattr(chunk.output, 'audio') and chunk.output.audio.data is not None:
                        wav_bytes = base64.b64decode(chunk.output.audio.data)
                        audio_chunks.append(wav_bytes)
                
                if audio_chunks:
                    # åˆå¹¶å¹¶ä¿å­˜éŸ³é¢‘
                    complete_audio = b''.join(audio_chunks)
                    with open(file_path, 'wb') as f:
                        f.write(complete_audio)
                    
                    print(f"âœ… è¯­éŸ³ç”ŸæˆæˆåŠŸ ({self.model}): {file_name}")
                    return str(file_path)
                else:
                    print(f"âš ï¸ {self.model} ç”Ÿæˆå¤±è´¥ï¼Œå°è¯•æ—§æ¨¡å‹")
                    raise Exception("No audio data")
            
            except Exception as e:
                # å¦‚æœæ–° API å¤±è´¥ï¼Œå›é€€åˆ°æ—§æ¨¡å‹ (SpeechSynthesizer)
                print(f"âš ï¸ {self.model} å¤±è´¥ ({e})ï¼Œä½¿ç”¨æ—§æ¨¡å‹")
                
                # éŸ³è‰²æ˜ å°„ï¼ˆæ–°æ¨¡å‹éŸ³è‰² -> æ—§æ¨¡å‹éŸ³è‰²ï¼‰
                voice_mapping = {
                    "Cherry": "zhixiaobai",
                    "Bella": "zhixiaoxia",
                    "Amy": "zhiyan",
                }
                old_voice = voice_mapping.get(voice, "zhixiaobai")
                
                result = SpeechSynthesizer.call(
                    model='sambert-zhichu-v1',
                    text=text,
                    sample_rate=self.sample_rate,
                    format=self.format,
                    voice=old_voice
                )
                
                if result.get_audio_data() is not None:
                    with open(file_path, 'wb') as f:
                        f.write(result.get_audio_data())
                    
                    print(f"âœ… è¯­éŸ³ç”ŸæˆæˆåŠŸ (æ—§æ¨¡å‹): {file_name}")
                    return str(file_path)
                else:
                    print(f"âš ï¸ TTS ç”Ÿæˆå¤±è´¥: {result}")
                    return None
        
        except Exception as e:
            print(f"âŒ TTS ç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    async def text_to_speech_stream(
        self, 
        text: str, 
        player_id: Optional[int] = None,
        voice: Optional[str] = None,
        speed: Optional[float] = None,
        pitch: Optional[float] = None
    ):
        """
        æµå¼ç”Ÿæˆè¯­éŸ³ï¼ˆç”Ÿæˆå®Œæ•´éŸ³é¢‘åè¿”å›ï¼‰
        
        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            player_id: ç©å®¶ID
            voice: éŸ³è‰²ï¼ˆå¯é€‰ï¼Œè¦†ç›–é»˜è®¤éŸ³è‰²ï¼‰
            speed: è¯­é€Ÿï¼ˆå¯é€‰ï¼Œè¦†ç›–é»˜è®¤è¯­é€Ÿï¼‰
            pitch: éŸ³é«˜ï¼ˆå¯é€‰ï¼Œè¦†ç›–é»˜è®¤éŸ³é«˜ï¼‰
        
        Yields:
            éŸ³é¢‘æ•°æ®å—ï¼ˆbase64ç¼–ç çš„å­—ç¬¦ä¸²ï¼‰
        """
        if not text or not self.api_key:
            return
        
        # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°æˆ–é»˜è®¤å‚æ•°
        voice = voice or self.voice
        speed = speed if speed is not None else self.speed
        pitch = pitch if pitch is not None else self.pitch
        
        try:
            print(f"ğŸµ å¼€å§‹TTSç”Ÿæˆ: ç©å®¶{player_id}, æ–‡æœ¬é•¿åº¦={len(text)}, éŸ³è‰²={voice}")
            
            # ä½¿ç”¨é…ç½®çš„ TTS æ¨¡å‹
            try:
                response = dashscope.MultiModalConversation.call(
                    api_key=self.api_key,
                    model=self.model,
                    text=text,
                    voice=voice,
                    language_type="Chinese",
                    stream=True
                )
                
                # çœŸæ­£çš„æµå¼ï¼šé€å—è¿”å›éŸ³é¢‘æ•°æ®ï¼ˆä¸ç­‰å¾…å…¨éƒ¨å®Œæˆï¼‰
                chunk_count = 0
                total_bytes = 0
                first_chunk = True
                
                for chunk in response:
                    if hasattr(chunk.output, 'audio') and chunk.output.audio.data is not None:
                        # ç›´æ¥è¿”å›æ¯ä¸ªéŸ³é¢‘å—ï¼ˆå·²ç»æ˜¯ base64 ç¼–ç ï¼‰
                        audio_chunk_base64 = chunk.output.audio.data
                        audio_bytes = base64.b64decode(audio_chunk_base64)
                        
                        # æ£€æµ‹ç¬¬ä¸€ä¸ªå—çš„éŸ³é¢‘æ ¼å¼
                        if first_chunk and len(audio_bytes) >= 8:
                            magic_bytes = ' '.join([f'{b:02x}' for b in audio_bytes[:8]])
                            print(f"ğŸ” éŸ³é¢‘æ ¼å¼æ£€æµ‹ (ç©å®¶{player_id}): å‰8å­—èŠ‚={magic_bytes}")
                            
                            # æ£€æµ‹æ ¼å¼
                            if audio_bytes[:4] == b'RIFF':
                                print(f"âœ… æ£€æµ‹åˆ° WAV æ ¼å¼")
                            elif audio_bytes[:3] == b'ID3' or (audio_bytes[0] == 0xFF and (audio_bytes[1] & 0xE0) == 0xE0):
                                print(f"âœ… æ£€æµ‹åˆ° MP3 æ ¼å¼")
                            elif audio_bytes[:4] == b'OggS':
                                print(f"âœ… æ£€æµ‹åˆ° OGG æ ¼å¼")
                            else:
                                print(f"âš ï¸ æœªçŸ¥éŸ³é¢‘æ ¼å¼")
                            
                            first_chunk = False
                        
                        chunk_count += 1
                        total_bytes += len(audio_bytes)
                        yield audio_chunk_base64
                        print(f"ğŸ“¦ å‘é€éŸ³é¢‘å— #{chunk_count} (ç©å®¶{player_id}): {len(audio_bytes)} bytes")
                        await asyncio.sleep(0)  # è®©å‡ºæ§åˆ¶æƒ
                
                if chunk_count > 0:
                    print(f"âœ… TTSç”Ÿæˆå®Œæˆ ({self.model}): ç©å®¶{player_id}, å…±{chunk_count}å—, æ€»å¤§å°={total_bytes} bytes")
                else:
                    print(f"âš ï¸ {self.model} ç”Ÿæˆå¤±è´¥ï¼Œå°è¯•æ—§æ¨¡å‹")
                    raise Exception("No audio data")
            
            except Exception as e:
                # å¦‚æœæ–° API å¤±è´¥ï¼Œå›é€€åˆ°æ—§æ¨¡å‹ï¼ˆéæµå¼ï¼‰
                print(f"âš ï¸ {self.model}å¤±è´¥ ({e})ï¼Œä½¿ç”¨æ—§æ¨¡å‹")
                
                # éŸ³è‰²æ˜ å°„
                voice_mapping = {
                    "Cherry": "zhixiaobai",
                    "Bella": "zhixiaoxia",
                    "Amy": "zhiyan",
                }
                old_voice = voice_mapping.get(voice, "zhixiaobai")
                
                result = SpeechSynthesizer.call(
                    model='sambert-zhichu-v1',
                    text=text,
                    sample_rate=self.sample_rate,
                    format=self.format,
                    voice=old_voice
                )
                
                if result.get_audio_data() is not None:
                    # æ—§æ¨¡å‹ä¸æ”¯æŒæµå¼ï¼Œç›´æ¥è¿”å›å®Œæ•´éŸ³é¢‘çš„base64
                    audio_data = result.get_audio_data()
                    audio_base64 = base64.b64encode(audio_data).decode('utf-8')
                    yield audio_base64
                    print(f"âœ… è¯­éŸ³ç”ŸæˆæˆåŠŸ (æ—§æ¨¡å‹): ç©å®¶{player_id}")
                else:
                    print(f"âš ï¸ TTS ç”Ÿæˆå¤±è´¥: {result}")
        
        except Exception as e:
            print(f"âŒ TTSç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def get_config(self) -> Dict[str, Any]:
        """
        è·å–å½“å‰é…ç½®
        
        Returns:
            é…ç½®å­—å…¸
        """
        return {
            "model": self.model,
            "voice": self.voice,
            "speed": self.speed,
            "pitch": self.pitch,
            "volume": self.volume,
            "sample_rate": self.sample_rate,
            "format": self.format
        }


# ==================== å…¨å±€å®ä¾‹ ====================

_dashscope_tts_instance: Optional[DashScopeTTSService] = None


def get_dashscope_tts_service(reload: bool = False) -> DashScopeTTSService:
    """
    è·å–å…¨å±€ DashScope TTS æœåŠ¡å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
    
    Args:
        reload: æ˜¯å¦é‡æ–°åŠ è½½å®ä¾‹
    
    Returns:
        DashScopeTTSService å®ä¾‹
    """
    global _dashscope_tts_instance
    
    if _dashscope_tts_instance is None or reload:
        _dashscope_tts_instance = DashScopeTTSService(use_config=True)
    
    return _dashscope_tts_instance


def reload_tts_service() -> DashScopeTTSService:
    """é‡æ–°åŠ è½½TTSæœåŠ¡"""
    return get_dashscope_tts_service(reload=True)


# ==================== TTSå·¥å‚ï¼ˆæ”¯æŒå¤šç§æä¾›å•†ï¼‰ ====================

class TTSFactory:
    """TTSå·¥å‚ç±» - ç”¨äºåˆ›å»ºä¸åŒæä¾›å•†çš„TTSæœåŠ¡"""
    
    @staticmethod
    def create_tts(provider: Optional[str] = None, **kwargs):
        """
        åˆ›å»ºTTSæœåŠ¡å®ä¾‹
        
        Args:
            provider: TTSæä¾›å•†ï¼ˆdashscope, azure, elevenlabsï¼‰
                     å¦‚æœä¸ºNoneï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æä¾›å•†
            **kwargs: é¢å¤–çš„TTSå‚æ•°
        
        Returns:
            TTSæœåŠ¡å®ä¾‹
        
        Raises:
            ValueError: å¦‚æœæä¾›å•†ä¸æ”¯æŒ
        """
        if provider is None:
            from src.utils.config import get_config
            config = get_config()
            provider = config.tts_provider
        
        if provider == "dashscope":
            return DashScopeTTSService(**kwargs)
        
        elif provider == "azure":
            raise NotImplementedError("Azure TTS æš‚æœªå®ç°")
        
        elif provider == "elevenlabs":
            raise NotImplementedError("ElevenLabs TTS æš‚æœªå®ç°")
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„TTSæä¾›å•†: {provider}")


def create_tts_from_config(provider: Optional[str] = None):
    """
    ä»é…ç½®åˆ›å»ºTTSæœåŠ¡å®ä¾‹ï¼ˆä¾¿æ·å‡½æ•°ï¼‰
    
    Args:
        provider: TTSæä¾›å•†ï¼ˆå¦‚æœä¸ºNoneï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æä¾›å•†ï¼‰
    
    Returns:
        TTSæœåŠ¡å®ä¾‹
    """
    return TTSFactory.create_tts(provider)
