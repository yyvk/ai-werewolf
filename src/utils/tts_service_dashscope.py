"""
è¯­éŸ³åˆæˆæœåŠ¡ - ä½¿ç”¨ DashScope API
é˜¿é‡Œäº‘çš„è¯­éŸ³åˆæˆæœåŠ¡
"""

import os
import asyncio
import base64
from typing import Optional
from pathlib import Path

try:
    import dashscope
    from dashscope.audio.tts import SpeechSynthesizer
    DASHSCOPE_AVAILABLE = True
except ImportError:
    DASHSCOPE_AVAILABLE = False
    print("âš ï¸ dashscope æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install dashscope")


class DashScopeTTSService:
    """DashScope è¯­éŸ³åˆæˆæœåŠ¡ç±»"""
    
    def __init__(self, api_key: Optional[str] = None, model: Optional[str] = None, voice: Optional[str] = None):
        """
        åˆå§‹åŒ– TTS æœåŠ¡
        
        Args:
            api_key: DashScope APIå¯†é’¥
            model: TTSæ¨¡å‹åç§°
            voice: éŸ³è‰²åç§°
        """
        if not DASHSCOPE_AVAILABLE:
            raise ImportError("dashscope åº“æœªå®‰è£…")
        
        # ä¼˜å…ˆä½¿ç”¨ DASHSCOPE_API_KEYï¼ˆç”¨äºTTSï¼‰ï¼Œå…¶æ¬¡ä½¿ç”¨ OPENAI_API_KEY
        # è¿™æ ·å¯ä»¥è®© LLM ç”¨ ModelScopeï¼ŒTTS ç”¨ DashScope
        self.api_key = api_key or os.getenv("DASHSCOPE_API_KEY") or os.getenv("OPENAI_API_KEY", "")
        dashscope.api_key = self.api_key
        
        # ä»é…ç½®æ–‡ä»¶è¯»å–æ¨¡å‹åç§°
        self.model = model or os.getenv("TTS_MODEL", "qwen3-tts-flash")
        
        # DashScope æ”¯æŒçš„éŸ³è‰²
        # Qwen3-TTS-Flash é»˜è®¤éŸ³è‰²ï¼šCherry
        # æ—§æ¨¡å‹é»˜è®¤éŸ³è‰²ï¼šzhixiaobai
        self.voice = voice or os.getenv("TTS_VOICE", "Cherry")
        
        # è®¾ç½® DashScope API åœ°å€ï¼ˆåŒ—äº¬åœ°åŸŸï¼‰
        dashscope.base_http_api_url = 'https://dashscope.aliyuncs.com/api/v1'
        
        # éŸ³é¢‘è¾“å‡ºç›®å½•
        self.output_dir = Path(__file__).parent.parent.parent / "assets" / "audio"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ”Š DashScope TTSæœåŠ¡åˆå§‹åŒ–: æ¨¡å‹={self.model}, éŸ³è‰²={self.voice}")
    
    async def text_to_speech(self, text: str, player_id: Optional[int] = None) -> Optional[str]:
        """
        å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³
        
        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            player_id: ç©å®¶IDï¼ˆç”¨äºç”Ÿæˆæ–‡ä»¶åï¼‰
            
        Returns:
            éŸ³é¢‘æ–‡ä»¶çš„è·¯å¾„ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
        """
        if not text or not self.api_key:
            return None
        
        try:
            # ç”Ÿæˆæ–‡ä»¶å
            file_name = f"speech_{player_id}_{hash(text) % 100000}.wav"
            file_path = self.output_dir / file_name
            
            # ä½¿ç”¨é…ç½®çš„ TTS æ¨¡å‹
            try:
                response = dashscope.MultiModalConversation.call(
                    api_key=self.api_key,
                    model=self.model,
                    text=text,
                    voice=self.voice,
                    language_type="Chinese",
                    stream=True
                )
                
                # æ”¶é›†æ‰€æœ‰éŸ³é¢‘æ•°æ®
                audio_chunks = []
                for chunk in response:
                    if hasattr(chunk.output, 'audio') and chunk.output.audio.data is not None:
                        wav_bytes = base64.b64decode(chunk.output.audio.data)
                        audio_chunks.append(wav_bytes)
                
                if audio_chunks:
                    # åˆå¹¶å¹¶ä¿å­˜éŸ³é¢‘
                    complete_audio = b''.join(audio_chunks)
                    with open(file_path, 'wb') as f:
                        f.write(complete_audio)
                    
                    print(f"âœ… è¯­éŸ³ç”ŸæˆæˆåŠŸ (Qwen3-TTS): {file_name}")
                    return str(file_path)
                else:
                    print(f"âš ï¸ Qwen3-TTS ç”Ÿæˆå¤±è´¥ï¼Œå°è¯•æ—§æ¨¡å‹")
                    raise Exception("No audio data")
                    
            except Exception as e:
                # å¦‚æœæ–° API å¤±è´¥ï¼Œå›é€€åˆ°æ—§æ¨¡å‹ (SpeechSynthesizer)
                print(f"âš ï¸ Qwen3-TTS å¤±è´¥ ({e})ï¼Œä½¿ç”¨æ—§æ¨¡å‹")
                
                result = SpeechSynthesizer.call(
                    model='sambert-zhichu-v1',
                    text=text,
                    sample_rate=16000,
                    format='wav',
                    voice='zhixiaobai' if self.voice == 'Cherry' else self.voice
                )
                
                if result.get_audio_data() is not None:
                    with open(file_path, 'wb') as f:
                        f.write(result.get_audio_data())
                    
                    print(f"âœ… è¯­éŸ³ç”ŸæˆæˆåŠŸ (æ—§æ¨¡å‹): {file_name}")
                    return str(file_path)
                else:
                    print(f"âš ï¸ TTS ç”Ÿæˆå¤±è´¥: {result}")
                    return None
                
        except Exception as e:
            print(f"âŒ TTS ç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    async def text_to_speech_stream(self, text: str, player_id: Optional[int] = None):
        """
        æµå¼ç”Ÿæˆè¯­éŸ³ï¼ˆç”Ÿæˆå®Œæ•´éŸ³é¢‘åè¿”å›ï¼‰
        
        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            player_id: ç©å®¶ID
            
        Yields:
            éŸ³é¢‘æ•°æ®å—ï¼ˆbase64ç¼–ç çš„å­—ç¬¦ä¸²ï¼‰
        """
        if not text or not self.api_key:
            return
        
        try:
            print(f"ğŸµ å¼€å§‹TTSç”Ÿæˆ: ç©å®¶{player_id}, æ–‡æœ¬é•¿åº¦={len(text)}")
            
            # ä½¿ç”¨é…ç½®çš„ TTS æ¨¡å‹
            try:
                response = dashscope.MultiModalConversation.call(
                    api_key=self.api_key,
                    model=self.model,
                    text=text,
                    voice=self.voice,
                    language_type="Chinese",
                    stream=True
                )
                
                # æ”¶é›†æ‰€æœ‰éŸ³é¢‘æ•°æ®
                audio_chunks = []
                for chunk in response:
                    if hasattr(chunk.output, 'audio') and chunk.output.audio.data is not None:
                        wav_bytes = base64.b64decode(chunk.output.audio.data)
                        audio_chunks.append(wav_bytes)
                
                if audio_chunks:
                    # åˆå¹¶æ‰€æœ‰éŸ³é¢‘å—
                    complete_audio = b''.join(audio_chunks)
                    # è¿”å›å®Œæ•´çš„base64ç¼–ç éŸ³é¢‘
                    audio_base64 = base64.b64encode(complete_audio).decode('utf-8')
                    yield audio_base64
                    print(f"âœ… TTSç”ŸæˆæˆåŠŸ (Qwen3-TTS): ç©å®¶{player_id}, å¤§å°={len(complete_audio)} bytes")
                else:
                    print(f"âš ï¸ Qwen3-TTS ç”Ÿæˆå¤±è´¥ï¼Œå°è¯•æ—§æ¨¡å‹")
                    raise Exception("No audio data")
                    
            except Exception as e:
                # å¦‚æœæ–° API å¤±è´¥ï¼Œå›é€€åˆ°æ—§æ¨¡å‹ï¼ˆéæµå¼ï¼‰
                print(f"âš ï¸ Qwen3-TTSå¤±è´¥ ({e})ï¼Œä½¿ç”¨æ—§æ¨¡å‹")
                
                result = SpeechSynthesizer.call(
                    model='sambert-zhichu-v1',
                    text=text,
                    sample_rate=16000,
                    format='wav',
                    voice='zhixiaobai' if self.voice == 'Cherry' else self.voice
                )
                
                if result.get_audio_data() is not None:
                    # æ—§æ¨¡å‹ä¸æ”¯æŒæµå¼ï¼Œç›´æ¥è¿”å›å®Œæ•´éŸ³é¢‘çš„base64
                    audio_data = result.get_audio_data()
                    audio_base64 = base64.b64encode(audio_data).decode('utf-8')
                    yield audio_base64
                    print(f"âœ… è¯­éŸ³ç”ŸæˆæˆåŠŸ (æ—§æ¨¡å‹): ç©å®¶{player_id}")
                else:
                    print(f"âš ï¸ TTS ç”Ÿæˆå¤±è´¥: {result}")
                
        except Exception as e:
            print(f"âŒ TTSç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()


# å…¨å±€å®ä¾‹
_dashscope_tts_instance = None


def get_dashscope_tts_service() -> DashScopeTTSService:
    """è·å–å…¨å±€ DashScope TTS æœåŠ¡å®ä¾‹"""
    global _dashscope_tts_instance
    if _dashscope_tts_instance is None:
        # ä»é…ç½®æ–‡ä»¶è¯»å– TTS é…ç½®
        from src.utils.config import get_config
        config = get_config()
        _dashscope_tts_instance = DashScopeTTSService(
            model=config.tts_model if hasattr(config, 'tts_model') else None,
            voice=config.tts_voice if hasattr(config, 'tts_voice') else None
        )
    return _dashscope_tts_instance

