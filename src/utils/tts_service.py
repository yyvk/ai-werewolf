"""
è¯­éŸ³åˆæˆæœåŠ¡ (Text-to-Speech)
ä½¿ç”¨ ModelScope è¯­éŸ³åˆæˆæ¨¡å‹
"""

import os
import base64
import asyncio
from typing import Optional
import httpx
from pathlib import Path


class TTSService:
    """è¯­éŸ³åˆæˆæœåŠ¡ç±»"""
    
    def __init__(self, api_key: Optional[str] = None, model: Optional[str] = None, voice: Optional[str] = None):
        """
        åˆå§‹åŒ– TTS æœåŠ¡
        
        Args:
            api_key: ModelScope APIå¯†é’¥
            model: è¯­éŸ³åˆæˆæ¨¡å‹åç§°
            voice: éŸ³è‰²åç§°
        """
        # TTS ä¸“ç”¨çš„ API Keyï¼ˆä¼˜å…ˆä½¿ç”¨ DASHSCOPE_API_KEYï¼‰
        self.api_key = api_key or os.getenv("DASHSCOPE_API_KEY") or os.getenv("OPENAI_API_KEY", "")
        self.model = model or os.getenv("TTS_MODEL", "iic/speech_sambert-hifigan_tts_zh-cn_16k")
        # é˜¿é‡Œäº‘æ”¯æŒçš„éŸ³è‰²ï¼šzhixiaobai, zhixiaoxia, zhiyan, zhitian, zhigang ç­‰
        self.voice = voice or os.getenv("TTS_VOICE", "zhixiaobai")
        
        # é˜¿é‡Œäº‘ DashScope TTS API ç«¯ç‚¹
        self.api_base = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text2speech/synthesis"
        
        # éŸ³é¢‘è¾“å‡ºç›®å½•
        self.output_dir = Path(__file__).parent.parent.parent / "assets" / "audio"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ”Š TTSæœåŠ¡åˆå§‹åŒ–: æ¨¡å‹={self.model}, éŸ³è‰²={self.voice}")
        print(f"   API ç«¯ç‚¹: {self.api_base}")
    
    async def text_to_speech(self, text: str, player_id: Optional[int] = None) -> Optional[str]:
        """
        å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³
        
        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            player_id: ç©å®¶IDï¼ˆç”¨äºç”Ÿæˆæ–‡ä»¶åï¼‰
            
        Returns:
            éŸ³é¢‘æ–‡ä»¶çš„è·¯å¾„ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
        """
        if not text or not self.api_key:
            return None
        
        try:
            # å‡†å¤‡è¯·æ±‚
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            # é˜¿é‡Œäº‘ DashScope TTS API è¯·æ±‚æ ¼å¼
            payload = {
                "model": "sambert-zhichu-v1",
                "input": {
                    "text": text
                },
                "parameters": {
                    "voice": self.voice,
                    "format": "wav",
                    "sample_rate": 16000,
                    "volume": 50
                }
            }
            
            # å‘é€è¯·æ±‚
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    self.api_base,
                    json=payload,
                    headers=headers
                )
                
                if response.status_code != 200:
                    print(f"âš ï¸ TTS API é”™è¯¯: {response.status_code}")
                    print(f"   è¯·æ±‚ URL: {self.api_base}")
                    print(f"   å“åº”å†…å®¹: {response.text[:200]}")
                    return None
                
                result = response.json()
                print(f"   å“åº”ç»“æ„: {list(result.keys())}")
                
                # ä»å“åº”ä¸­æå–éŸ³é¢‘æ•°æ®
                # é˜¿é‡Œäº‘ DashScope è¿”å›æ ¼å¼: {"output": {"audio_url": "..."}}
                if "output" in result:
                    output = result["output"]
                    
                    # æ–¹å¼1: è¿”å› URL
                    if "audio_url" in output:
                        audio_url = output["audio_url"]
                        print(f"   ä¸‹è½½éŸ³é¢‘: {audio_url}")
                        audio_response = await client.get(audio_url)
                        
                        if audio_response.status_code == 200:
                            file_name = f"speech_{player_id}_{hash(text) % 100000}.wav"
                            file_path = self.output_dir / file_name
                            
                            with open(file_path, "wb") as f:
                                f.write(audio_response.content)
                            
                            print(f"âœ… è¯­éŸ³ç”ŸæˆæˆåŠŸ: {file_name}")
                            return str(file_path)
                    
                    # æ–¹å¼2: è¿”å› base64 ç¼–ç çš„éŸ³é¢‘
                    elif "audio" in output:
                        audio_data = output["audio"]
                        if isinstance(audio_data, str):
                            audio_bytes = base64.b64decode(audio_data)
                        else:
                            audio_bytes = audio_data
                        
                        file_name = f"speech_{player_id}_{hash(text) % 100000}.wav"
                        file_path = self.output_dir / file_name
                        
                        with open(file_path, "wb") as f:
                            f.write(audio_bytes)
                        
                        print(f"âœ… è¯­éŸ³ç”ŸæˆæˆåŠŸ: {file_name}")
                        return str(file_path)
                
                print(f"âš ï¸ TTS å“åº”ä¸­æ²¡æœ‰éŸ³é¢‘æ•°æ®")
                print(f"   å®Œæ•´å“åº”: {result}")
                return None
                
        except Exception as e:
            print(f"âŒ TTS ç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    async def text_to_speech_stream(self, text: str, player_id: Optional[int] = None):
        """
        æµå¼æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆå½“æ–‡æœ¬è¾ƒé•¿æ—¶åˆ†æ®µå¤„ç†ï¼‰
        
        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            player_id: ç©å®¶ID
            
        Yields:
            éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        """
        # å°†é•¿æ–‡æœ¬åˆ†æ®µï¼ˆæŒ‰å¥å­åˆ†ï¼‰
        import re
        sentences = re.split(r'([ã€‚ï¼ï¼Ÿ.!?])', text)
        
        # é‡æ–°ç»„åˆå¥å­å’Œæ ‡ç‚¹
        segments = []
        for i in range(0, len(sentences) - 1, 2):
            if i + 1 < len(sentences):
                segments.append(sentences[i] + sentences[i + 1])
            else:
                segments.append(sentences[i])
        
        # å¦‚æœæ²¡æœ‰åˆ†æ®µï¼Œç›´æ¥å¤„ç†æ•´ä¸ªæ–‡æœ¬
        if not segments:
            segments = [text]
        
        # ä¸ºæ¯ä¸ªåˆ†æ®µç”Ÿæˆè¯­éŸ³
        for i, segment in enumerate(segments):
            if segment.strip():
                audio_path = await self.text_to_speech(segment, player_id)
                if audio_path:
                    yield audio_path
                    await asyncio.sleep(0.1)  # çŸ­æš‚å»¶è¿Ÿ


# å…¨å±€ TTS æœåŠ¡å®ä¾‹
_tts_instance = None


def get_tts_service() -> TTSService:
    """è·å–å…¨å±€ TTS æœåŠ¡å®ä¾‹"""
    global _tts_instance
    if _tts_instance is None:
        _tts_instance = TTSService()
    return _tts_instance

